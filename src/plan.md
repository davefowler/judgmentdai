---
title: Plan
layout: default.hbs
bg-image: judgment-dai-future-earth.png
---
Plan to Keep the Future Human and Block Decider‑Level AGI

(straightforward, persuasive, no bureaucrat‑speak – a concrete playbook governments can execute today)

⸻

Why This Matters
	•	Judgment DAI: A super‑intelligent “Decider AI” would seize the apex slot in Earth’s decision hierarchy, overriding every human choice. Your essay lays out the moral stakes; this plan shows the levers we can pull before the gate slams shut.
	•	Feasibility, not fantasy:  Compute is concentrated, measurable, and chokepoint‑rich – far easier to police than plutonium or bioweapons inputs.  We can halt AGI progress without grinding narrow, beneficial AI to a halt.

Key sources
: Computing Power & the Governance of AI (GovAI, 2024), AI Governance to Avoid Extinction (MIRI, 2025), Keep the Future Human (Aguirre, 2025), Gladstone AI Action Plan (2024), and the OpenAI‑affiliated compute‑governance report (arXiv:2402.08797).  These papers converge on three leverage points – compute, law, and coordinated enforcement – which anchor the plan below.

⸻

Pillar 1 — Register & Control Compute

Goal: Make every stack of frontier‑class silicon visible and licensable inside 18 months.
	1.	Statutory ceiling.  Ban the unauthorised possession or rental of clusters exceeding 10^23 training FLOP (≈ today’s GPT‑4 scale).  Threshold auto‑drops with Moore’s Law (e.g. halve FLOP limit every 18 months) to stay ahead of scaling.
	2.	National Compute Ledger.  Mandatory registration of:
	•	all GPUs/ASICs with ≥ 100 TFLOP s‑FP16
	•	datacenter racks connecting ≥ 1 PFLOP total
	•	relevant power draw & cooling footprint (easy to cross‑check via utilities).
	3.	Chip‑level attestation.  Require domestic fabs and importers to flash secure ID firmware (like a TPM on steroids).  Chips phone home to the Ledger; non‑auth chips throttle to <1% speed.
	4.	Cloud KYC.  Cloud providers must verify customers, log large‑scale training jobs, and stream telemetry to the Ledger.
	5.	Export & re‑export controls.  Extend October 2022 BIS rules: no unlicensed shipment of frontier AI chips or advanced lithography gear.  Violations = felony plus equipment forfeiture.
	6.	Audit & seizure unit.  A small, dedicated task force (think IRS‑meets‑NRC) with power to subpoena utility data, raid unregistered sites, and physically disable rogue clusters.

Why it works: The GovAI report shows > 90 % of leading‑edge AI silicon is designed by three firms and fabbed by one (TSMC).  That supply‑chain choke gives us the enforcement grip nukes never had.

⸻

Pillar 2 — Outlaw AGI, License Narrow AI

Goal: Draw a bright red line: no systems that combine High Autonomy + High Generality + High Intelligence.
	1.	Legal definition (plain‑English):
“Artificial General Intelligence means any machine‑learning system that, without domain‑specific retraining: (a) surpasses the best 10 % of human experts across ≥ 50 distinct cognitive benchmarks, and (b) can execute self‑directed long‑horizon plans (≥ 1 day) in the physical or digital world.”
	2.	Total prohibition.  Training, deploying, or even possessing AGI‑class weights is a strict‑liability offense (mirrors US ban on personal bioweapons stockpiles).
	3.	Narrow‑AI licensing.  Any model trained above the compute ceiling but below AGI threshold needs:
	•	a safety report (red‑teaming, misuse scenarios)
	•	provenance logs (datasets, hyper‑params)
	•	an “alignment bond” (cash or insured surety, forfeited if the model causes defined harms).
	4.	Model redlines.  Categorical bans on autonomous bio‑design, offensive cyber‑ops, political persuasion at scale, and long‑range autonomous weapons—consistent with Gladstone AI LOE‑recommendations.
	5.	Penalties.  Fines up to the larger of $10 B or 10× training cost; individual prison terms for executives who OK unlawful runs.

Why it works:  The MIRI Off‑Switch & Halt scenario argues we must be able to pull a universal brake.  Outlawing AGI class‑wide, rather than whack‑a‑mole safety standards, keeps the rulebook simple and enforceable.

⸻

Pillar 3 — Build the Enforcement Spine & Globalize It

Domestic first (Year 1–2)
	1.	Create the AI Safety & Compute Control Agency (AISCCA).  Seat it inside the Department of Commerce; give it NRC‑style independent powers.
	2.	Fusion‑cell monitoring.  Merge IRS power‑data, FCC spectrum data, and cloud telemetry into one real‑time dashboard flagged for suspicious GPU clusters.
	3.	Rapid‑response seals.  AISCCA teams can arrive on‑site within 24 h to image disks, pull breakers, and secure weights.

Link‑up phase (Year 2–4)
4. Compute Non‑Proliferation Treaty (CNPT).  Invite G7 + Taiwan, South Korea, Netherlands (ASML), Singapore, Israel to lock export controls and chip‑firmware standards.
5. International Compute Control Authority (ICCA).  Modeled on IAEA; grants inspectors snap‑access to large datacenters, fab output logs, and cloud telemetry portals.
6. Mutual‑profit carrots.  Offer “Compute for Good” credits—cheap, regulated inference capacity for health, climate, and education—to allied states that ratify CNPT.
7. Deterrence & penalties.  Sanctions, export bans, and financial blacklisting for states or firms caught training outlawed models; seizure of offending hardware (made worthless by firmware kill‑codes anyway).

Why it works:  AGI training runs need thousands of chips for months.  With firmware attest, satellite‑power signatures, and trade choke points, covert large‑scale runs become nearly impossible.  Nuclear safeguards took decades to mature; compute safeguards piggyback on an already centralized industry.

⸻

Implementation Timeline (Aggressive but Achievable)

Phase	0‑6 mo	6‑18 mo	18‑36 mo	36‑60 mo
Legislation	Draft compute‑ledger & AGI ban bill; emergency export‑control update	Bill passes; AISCCA funded	Alignment‑bond regs finalized	CNPT treaty text signed
Tech stack	Firmware spec published; pilot KYC at AWS/GCP/Azure	Mass chip flashing at fabs; national ledger live	Real‑time cloud telemetry feed; power‑sat monitoring	Global ICCA inspectors operational
Enforcement	Temporary moratorium on >10^25 FLOP training runs	First audits, seizures if needed; civil fines	Criminal prosecutions; public compliance dashboard	Routine global inspections



⸻

End State
	•	Zero AGI capability on the planet.  All compute above threshold is either idle, aligned research, or narrow, licensed AI.
	•	Permanent Off‑Switch.  Any attempt to scale beyond limits triggers alarms at the chip, cloud, and treaty levels.
	•	Human‑First AI Ecosystem.  Narrow tools flourish under a clear ceiling; economic and research gains accrue without risking a Decider takeover.

⸻

Key References
	•	GovAI – Computing Power and the Governance of AI (2024): https://www.governance.ai/analysis/computing-power-and-the-governance-of-ai
	•	Sastry et al. – Computing Power & the Governance of AI (arXiv:2402.08797).
	•	MIRI – AI Governance to Avoid Extinction (2025): https://intelligence.org/wp-content/uploads/2025/05/AI-Governance-to-Avoid-Extinction.pdf
	•	Aguirre – Keep the Future Human (2025): https://keepthefuturehuman.ai/wp-content/uploads/2025/03/Keep_the_Future_Human__AnthonyAguirre__5March2025.pdf
	•	Gladstone AI – An Action Plan to Increase the Safety and Security of Advanced AI (2024): https://cdn.slow-news.com/wp-content/uploads/2024/03/Gladstone-Action-Plan.pdf

(Add any future research links in this section as the literature evolves.)

⸻

“The only way to win is not to play.”  This plan shows exactly how to stop the game – before a Decider AI makes the moves for us.